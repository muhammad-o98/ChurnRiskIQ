# Telecom Churn Prediction - Complete ML & Analytics Platform

An end-to-end machine learning platform for telecom customer churn prediction, featuring:
- **Interactive Streamlit Web Application** with modern UI/UX
- **6 ML Models**: Decision Tree, Random Forest, Gradient Boosting, XGBoost, LightGBM, CatBoost
- **SHAP Analysis** for model explainability
- **Risk Segmentation** with retention strategies
- **Executive Dashboard** with KPIs and insights

---

## ðŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run the Streamlit App
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

---

## ðŸ“Š Application Features

### ðŸ  **Home Page**
- Project overview and navigation
- Quick metrics dashboard
- Feature highlights

### ðŸ“¤ **Data Upload & Preprocessing**
- Upload your own CSV or use sample data
- Automated data cleaning and preprocessing
- Feature engineering (6 new features)
- Interactive visualizations (distributions, correlations)

### ðŸ¤– **Model Training**
- Train multiple models simultaneously
- Real-time progress tracking
- Model comparison with 10+ metrics
- ROC curves and confusion matrices

### ðŸ” **SHAP Analysis**
- Feature importance visualization
- SHAP summary plots
- Top churn drivers analysis
- Supports both TreeExplainer and KernelExplainer

### âš ï¸ **Risk Segmentation**
- Customer segmentation (High/Medium/Low risk)
- Churn probability scoring
- Retention strategies per segment
- Export customer lists

### ðŸ“Š **Executive Dashboard**
- KPIs and metrics overview
- Model performance summary
- Risk distribution insights
- Executive summary report
- Export capabilities

---

## ðŸ“ Project Structure

```
telecom-churn/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ pages/                          # Multi-page app structure
â”‚   â”œâ”€â”€ 1_ðŸ“¤_Data_Upload.py        # Data upload and preprocessing
â”‚   â”œâ”€â”€ 2_ðŸ¤–_Model_Training.py     # Model training and comparison
â”‚   â”œâ”€â”€ 3_ðŸ”_SHAP_Analysis.py      # SHAP explainability
â”‚   â”œâ”€â”€ 4_âš ï¸_Risk_Segmentation.py  # Customer risk segments
â”‚   â””â”€â”€ 5_ðŸ“Š_Dashboard.py          # Executive dashboard
â”œâ”€â”€ utils/                          # Utility modules
â”‚   â”œâ”€â”€ session_state.py           # Session state management
â”‚   â”œâ”€â”€ data_utils.py              # Data preprocessing
â”‚   â””â”€â”€ model_utils.py             # Model training & evaluation
â”œâ”€â”€ data/
â”‚   â””â”€â”€ churndata.csv              # Sample dataset
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ telecom_churn.ipynb        # Jupyter notebook analysis
â””â”€â”€ src/                           # CLI pipeline (optional)
    â”œâ”€â”€ main.py
    â”œâ”€â”€ churn_pipeline.py
    â””â”€â”€ ...
```

---

## ðŸ”§ Configuration-Driven CLI Pipeline

For advanced users, a config-driven CLI pipeline is also available:

### Configure
Edit [config/config.yaml](config/config.yaml):
- data.path: path to your CSV
- models.base_models: select models to run
- tuning.param_grids: hyperparameter grids
- tuning.strategy: "grid" or "random"

### Run Modes
- Quick: run ALL configured models (no tuning), then pick best
```bash
python src/main.py --mode quick
# -> train (all models, no tuning) -> pick-best
```

- Quick Grid: run ALL models with GridSearchCV, then pick best
```bash
python src/main.py --mode quick-grid
# -> tune (grid) (all models) -> pick-best
```

- Full: complete pipeline honoring tuning strategy in config (grid or random)
```bash
python src/main.py --mode full
# -> prepare â†’ tune/train â†’ evaluate (+plots) â†’ ensemble â†’ pick best
```

- Evaluate and pick (use already-saved models)
```bash
python src/main.py --mode eval-pick
# -> eval all saved models -> pick best
```

- Custom (select stages and/or model subset)
```bash
# By stages (any subset of prep,tune,train,eval,pick), in order:
python src/main.py --mode custom --stages train,eval,pick

# By model keys:
python src/main.py --mode custom --models xgb_tuned lgbm_tuned svc
```

Prediction on new CSV (uses best model unless --model is specified):
```bash
python src/main.py --predict data/new_customers.csv
python src/main.py --predict data/new_customers.csv --model xgb_tuned --threshold 0.45
```

## Direct pipeline (advanced) â€“ src/churn_pipeline.py
```bash
python src/churn_pipeline.py --mode full
python src/churn_pipeline.py --mode train
python src/churn_pipeline.py --mode tune --tune-strategy grid
python src/churn_pipeline.py --mode tune --tune-strategy random --random-iter 50
python src/churn_pipeline.py --mode eval
python src/churn_pipeline.py --mode pick-best --metric f1
python src/churn_pipeline.py --mode full --models xgb_tuned lgbm_tuned svc
```

## Artifacts and Outputs
- Per-model directory: artifacts/models/<model_key>/
  - model.joblib â€“ fitted pipeline
  - cv_summary.json â€“ CV/tuning summary with timing
  - best_params.json + gridsearch_results.csv or randomsearch_results.csv (if tuned)
  - metrics.json â€“ test metrics including best_f1_threshold
  - prob_threshold_insights.json + prob_threshold_insights.txt
  - classification_report.txt
  - timing.json â€“ training/evaluation durations
  - figures/
    - confusion_matrix.png, roc_curve.png, pr_curve.png
    - f1_vs_threshold.png, cm_elements_vs_threshold.png
    - prob_by_actual_class.png, prob_by_outcome.png, prob_boxplot_by_outcome.png
    - feature_importances_top20.png (if available)
    - tree_top.png / rf_best_tree_top.png / gb_first_tree_top.png (where applicable)
    - shap_beeswarm.png, shap_bar.png, shap_dependence_*.png (for tree-based models)
  - shap_top_features.json (top features by |SHAP|)

- Ensemble: artifacts/models/soft_voting/model.joblib and soft_voting_metrics.json  
- Summary: artifacts/reports/summary_metrics.json  
- Best model: artifacts/models/best/best_model.joblib, best_model_name.txt  
- Predictions: artifacts/predictions/preds_<timestamp>.csv

## Notes
- SHAP is computed on a sample (max 500) for performance and only for tree-based models by default.
- Tree visualizations plot top levels for readability; adjust depth in code if needed.
- Some models parallelize internally; avoid heavy nested parallelism.
