{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabd629a",
   "metadata": {},
   "source": [
    "# SHAP plots for Telecom Churn\n",
    "\n",
    "This notebook creates three modern, well-labeled SHAP visualizations: a summary (beeswarm-like), a feature importance bar chart, and an interactive dependence plot.\n",
    "\n",
    "The cells include a small fallback: if you don't have a trained `model` and feature matrix `X`, the notebook will train a quick RandomForest on `data/churndata.csv` to demonstrate the plots.\n",
    "\n",
    "Requirements (install once):\n",
    "```\n",
    "pip install shap scikit-learn pandas matplotlib seaborn plotly\n",
    "```\n",
    ": \n",
    ",\n",
    ": {\n",
    ": \n",
    "\n",
    ": [\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    "whitegrid\", context=\"notebook\")\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: load dataset or create demo model if needed\n",
    "def prepare_demo_model(data_path='data/churndata.csv', target_col=None, sample_frac=0.5, random_state=42):\n",
    "    # Load CSV if available\n",
    "    if os.path.exists(data_path):\n",
    "        df = pd.read_csv(data_path)\n",
    "    else:\n",
    "        # Synthetic fallback if dataset not present\n",
    "        from sklearn.datasets import make_classification\n",
    "        Xs, ys = make_classification(n_samples=2000, n_features=12, n_informative=6, random_state=random_state)\n",
    "        df = pd.DataFrame(Xs, columns=[f'f{i}' for i in range(Xs.shape[1])])\n",
    "        df['target'] = ys\n",
    "    # Guess target column if not provided\n",
    "    if target_col is None:\n",
    "        if 'churn' in df.columns.str.lower():\n",
    "            possible = [c for c in df.columns if c.lower().endswith('churn') or 'churn' in c.lower()]\n",
    "            target_col = possible[0] if possible else df.columns[-1]\n",
    "        else:\n",
    "            target_col = df.columns[-1]\n",
    "    # Basic preprocessing: drop NAs, encode categoricals simply\n",
    "    df = df.dropna().copy()\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    for col in X.select_dtypes(include=['object', 'category']).columns:\n",
    "        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "    # Subsample for speed if large\n",
    "    X, _, y, _ = train_test_split(X, y, train_size=sample_frac, stratify=y, random_state=random_state)\n",
    "    # Train a quick tree model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "    model.fit(X, y)\n",
    "    return model, X, y\n",
    "\n",
    "# Create or reuse model/X from global scope if present\n",
    "try:\n",
    "    model  # noqa: F821\n",
    "    X  # noqa: F821\n",
    "    print(\"Using existing `model` and `X` from the environment.\")\n",
    "except NameError:\n",
    "    print(\"No existing model/X found — preparing a demo model. This may take ~30s.\")\n",
    "    model, X, y = prepare_demo_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: compute shap values with robust explainer selection\n",
    "def compute_shap_values(model, X, explainer_type_preference=['Tree','Kernel','Linear']):\n",
    "    \n",
    "    # Try TreeExplainer first for tree-based models\n",
    "    try:\n",
    "        if hasattr(shap, 'TreeExplainer'):\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X)\n",
    "            return explainer, shap_values\n",
    "    except Exception as e:\n",
    "        print(\"TreeExplainer failed: %s\" % e)\n",
    "    # Fallback to KernelExplainer (slower)\n",
    "    try:\n",
    "        if hasattr(shap, 'KernelExplainer'):\n",
    "            # use a small background sample for KernelExplainer\n",
    "            background = shap.sample(X, nsamples=min(50, X.shape[0]))\n",
    "            explainer = shap.KernelExplainer(model.predict_proba if hasattr(model, 'predict_proba') else model.predict, background)\n",
    "            shap_values = explainer.shap_values(X, nsamples=100)\n",
    "            return explainer, shap_values\n",
    "    except Exception as e:\n",
    "        print(\"KernelExplainer failed: %s\" % e)\n",
    "    # Last resort: approximate with permutation importance to show bar chart\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    r = permutation_importance(model, X, getattr(model, 'predict', lambda x: model.predict_proba(x)[:,1]), n_repeats=10, random_state=0, n_jobs=-1)\n",
    "    perm_importance = pd.Series(r.importances_mean, index=X.columns)\n",
    "    return None, perm_importance\n",
    "\n",
    "explainer, shap_values = compute_shap_values(model, X)\n",
    "print(\"Computed SHAP values (explainer: %s)\" % (type(explainer).__name__ if explainer is not None else 'None - permutation importance'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb929adf",
   "metadata": {},
   "source": [
    "## Plot 1 — SHAP summary (beeswarm-style)\n",
    "\n",
    "A compact, color-coded summary showing feature impact, ordered by importance. For large datasets we sample for the plot to keep it readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot (matplotlib + seaborn style)\n",
    "def plot_shap_summary(explainer, shap_values, X, max_display=20, sample_size=1000, title='SHAP summary plot'):\n",
    "    # If shap_values is a permutation importance Series, draw bar plot instead\n",
    "    if isinstance(shap_values, pd.Series):\n",
    "        vals = shap_values.sort_values(ascending=False).head(max_display)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=vals.values, y=vals.index, palette='viridis')\n",
    "        plt.title(title + ' (permutation importance)')\n",
    "        plt.xlabel('Importance (mean decrease)')\n",
    "        plt.tight_layout()\n",
    "        return\n",
    "    # shap_values may be a list (for classification with classes) or array\n",
    "    if isinstance(shap_values, list):\n",
    "        # choose the class with the largest mean absolute shap value\n",
    "        mags = [np.abs(s).mean() for s in shap_values]\n",
    "        idx = int(np.argmax(mags))\n",
    "        vals = shap_values[idx]\n",
    "    else:\n",
    "        vals = shap_values\n",
    "    # Sample rows for plotting clarity\n",
    "    if X.shape[0] > sample_size:\n",
    "        sample_idx = np.random.choice(X.index, size=sample_size, replace=False)\n",
    "        Xs = X.loc[sample_idx]\n",
    "        vals_sample = vals[sample_idx] if hasattr(vals, '__getitem__') else vals[sample_idx,:]\n",
    "    else:\n",
    "        Xs = X\n",
    "        vals_sample = vals\n",
    "    # Use SHAP's plotting if available for a clean beeswarm-style output but style it\n",
    "    plt.figure(figsize=(10,7))\n",
    "    try:\n",
    "        shap.summary_plot(vals_sample, Xs, show=False, max_display=max_display)\n",
    "        plt.title(title)\n",
    "    except Exception as e:\n",
    "        print(\"shap.summary_plot failed, falling back to bar chart: %s\" % e)\n",
    "        # fallback: mean(|SHAP|) bar plot\n",
    "        means = np.abs(vals).mean(axis=0)\n",
    "        order = np.argsort(means)[::-1][:max_display]\n",
    "        feats = X.columns[order]\n",
    "        sns.barplot(x=means[order], y=feats, palette='viridis')\n",
    "        plt.title(title + ' (mean |SHAP|)')\n",
    "        plt.xlabel('mean |SHAP value|')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_shap_summary(explainer, shap_values, X, max_display=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e4036",
   "metadata": {},
   "source": [
    "## Plot 2 — SHAP feature importance (horizontal bar)\n",
    "\n",
    "A clear horizontal bar chart using average absolute SHAP values to show global importance. For permutation fallback we use the same chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e84efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_importance(explainer, shap_values, X, top_n=20, title='SHAP feature importance'):\n",
    "    if isinstance(shap_values, pd.Series):\n",
    "        vals = shap_values.sort_values(ascending=False).head(top_n)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=vals.values, y=vals.index, palette='plasma')\n",
    "        plt.title(title + ' (permutation)')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        return\n",
    "    if isinstance(shap_values, list):\n",
    "        # aggregate across classes by mean absolute value\n",
    "        arr = np.mean([np.abs(s) for s in shap_values], axis=0)\n",
    "    else:\n",
    "        arr = np.abs(shap_values)\n",
    "        if arr.ndim == 2:\n",
    "            arr = np.mean(arr, axis=0)\n",
    "    means = pd.Series(arr, index=X.columns).sort_values(ascending=False).head(top_n)\n",
    "    plt.figure(figsize=(10, max(4, 0.35*len(means))))\n",
    "    sns.barplot(x=means.values, y=means.index, palette='plasma')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('mean |SHAP value|')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_shap_importance(explainer, shap_values, X, top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67ebf7",
   "metadata": {},
   "source": [
    "## Plot 3 — SHAP dependence plot (interactive with Plotly)\n",
    "\n",
    "Shows how a single feature affects predictions — we include color-coding by another feature and an interactive scatter for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594490be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_dependence_interactive(explainer, shap_values, X, feature=None, color_feature=None, title='SHAP dependence (interactive)'):\n",
    "    # If we only have permutation importance, fall back to static message\n",
    "    if isinstance(shap_values, pd.Series):\n",
    "        print('No shap values available for dependence plot (permutation importance only).')\n",
    "        return\n",
    "    # Determine shap matrix and choose column if multi-class\n",
    "    if isinstance(shap_values, list):\n",
    "        mags = [np.abs(s).mean() for s in shap_values]\n",
    "        idx = int(np.argmax(mags))\n",
    "        vals = shap_values[idx]\n",
    "    else:\n",
    "        vals = shap_values\n",
    "    # default feature: most important by mean abs\n",
    "    means = np.abs(vals).mean(axis=0)\n",
    "    if feature is None:\n",
    "        feature = X.columns[int(np.argmax(means))]\n",
    "    if color_feature is None:\n",
    "        # choose the second-most important feature to color by (if available)\n",
    "        order = np.argsort(means)[::-1]\n",
    "        color_idx = order[1] if len(order) > 1 else order[0]\n",
    "        color_feature = X.columns[int(color_idx)]\n",
    "    # build a DataFrame for plotting\n",
    "    shap_df = pd.DataFrame(vals, columns=X.columns, index=X.index)\n",
    "    plot_df = pd.DataFrame({\n",
    "        'feature_value': X[feature],\n",
    "        'shap_value': shap_df[feature],\n",
    "        'color_by': X[color_feature]\n",
    "    })\n",
    "    # Create interactive scatter colored by color_feature\n",
    "    fig = px.scatter(plot_df, x='feature_value', y='shap_value', color='color_by',\n",
    "                     color_continuous_scale='Turbo',\n",
    "                     title=f'{title}: {feature} (colored by {color_feature})',\n",
    "                     labels={'feature_value': f'{feature} value', 'shap_value': 'SHAP value', 'color_by': color_feature})\n",
    "    fig.update_traces(marker=dict(size=6, opacity=0.75))\n",
    "    fig.update_layout(height=500)\n",
    "    return fig\n",
    "\n",
    "fig = plot_shap_dependence_interactive(explainer, shap_values, X)\n",
    "# In a notebook this will display as interactive; in some viewers call fig.show()\n",
    "if fig is not None:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b01b3",
   "metadata": {},
   "source": [
    "## Notes and next steps\n",
    "\n",
    "- To improve visuals further, you can export the Plotly figure to HTML with `fig.write_html('dependence.html')`.\n",
    "- For very large datasets, compute SHAP on a sample or use model-approximation explainers.\n",
    "- If you have a trained model elsewhere in your repo (e.g., in `src/model_training.py`), import and pass it into the notebook environment to reuse the heavy work."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
